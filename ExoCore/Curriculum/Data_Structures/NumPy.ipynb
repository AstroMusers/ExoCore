{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a75992",
   "metadata": {},
   "source": [
    "# An Introduction to NumPy\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#introduction)\n",
    "- [Overview](#overview)\n",
    "- [Arrays](#arrays)\n",
    "    - [Basic Properties](#basic-properites)\n",
    "    - [Array Creation Methods]()\n",
    "    - [Example: Analyzing a 2D Image](#example-analyzing-a-2d-image)\n",
    "    - [Handling NANS](#handling-nans)\n",
    "    - [Stacking and Exporting Arrays](#stacking-and-exporting-arrays)\n",
    "    - [Sorting & Searching](#sorting--searching)\n",
    "- [Mathematical Routines](#mathematical-routines)\n",
    "    - [General Functions](#basic-mathematical-functions)\n",
    "    - [Statistics](#statistics)\n",
    "    - [Linear Algebra](#linear-algebra)\n",
    "    - [Simple Polynomial Regression Methods](#simple-polynomial-regression-methods)\n",
    "- [Exercises](#exercises)\n",
    "    - [Problem 1: Creating an Array in Four Different Ways](#problem-1-creating-an-array-in-four-different-ways)\n",
    "    - [Problem 2: Handling NANs](#problem-2-handling-nans)\n",
    "    - [Problem 3: Modeling Ingress and Egress](#problem-3-modeling-ingress-and-egress)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5cd3f3",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "The way we control, manipulate, and analyze data is an important process across all scientific disciplines. Exoplanet research is no different. The astronomical community has generally rallied behind **Python** (if you couldn't already tell from our use of Jupyter notebooks!) as the primary language for developing new data structures, computational methods, and robust analytical packages. These are amazing tools, but using them efficiently requires a solid foundation. This lesson gives a brief overview of the important capabilities behind `Numpy`, some interactive activities to visualize data (with some assistance from `PyPlot`), and how they are used in Exoplanet research.\n",
    "\n",
    " <div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "**IMPORTANT**: If you have limited exposure or practice with Python as a language, it is encouraged to get an understanding of basic syntax and proper use of variables. [Here](https://programming-23.mooc.fi/) is a self-paced, free course offered by the University of Helsinki that covers most of the important concepts in the first few modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86340312",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "`Numpy` is a robust Python package that incorporates many mathematical tools, data structures, and other useful routines that will be invaluable in your future as a researcher. By the end of this lesson we hope you will be able to:\n",
    "- **Create, manipulate, and analyze `Numpy` arrays**\n",
    "- **Utilize and employ the mathematical methods contained in `Numpy`**\n",
    "- **Visualize and interpret basic time-series and image data using `Numpy` methods**\n",
    "\n",
    "[Here](https://numpy.org/devdocs/) is the official documentation for `Numpy`!\n",
    "\n",
    "We can begin by running code to import `Numpy` to start. In Python, it is often convenient to import modules with the `as` clause, since it allows you to shorten package specific syntax when writing code. It is common practice to shorten `Numpy` to `np`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82173042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0d31cd",
   "metadata": {},
   "source": [
    "Now that we have `NumPy` imported, we can look at arrays!\n",
    "\n",
    "## Arrays\n",
    "[Here](https://numpy.org/devdocs/reference/arrays.html) is the official documentation for `Numpy` arrays.\n",
    "### Basic Properites\n",
    "In many ways, `Numpy` arrays are similar to base Python lists. They both can:\n",
    " - Store data\n",
    " - Are mutable\n",
    " - Be indexed and sliced\n",
    " - Can be iterated over using `for` loops\n",
    "\n",
    "`Numpy` arrays differ from lists in a few important ways:\n",
    "- Only one data type allowed (e.g. float, int, string)\n",
    "- Mathematical operations can be applied to the all elements in the array at once, without needing iteration\n",
    "- Arrays store memory efficiently, and have a fixed size in memory when created\n",
    "\n",
    "We will experiment with these different properties in the code below.\n",
    "\n",
    " <div class=\"alert alert-block alert-info\">\n",
    " \n",
    "**INFO**: There will be a lot of code output. If you want to keep your notebook tidy, click on the output box and click the 'O' (the letter, not '0') key to collapse the output box down without clearing your accumulated variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88d242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_oneD = np.array((0, 1, 1), dtype=float) #1D array of floats\n",
    "print(array_oneD, type(array_oneD[0]))\n",
    "array_twoD = np.array((('a','b'),('c','10')), dtype=str) #2D array of strings\n",
    "print(array_twoD, type(array_twoD[1,1]))\n",
    "N = 20\n",
    "array_N = np.zeros((N), dtype=int) #Generate an (N,1) array of zeros as ints \n",
    "for num in range(N):\n",
    "    array_N[num] = str(num) #Replace the zeros with an iterating number\n",
    "print(array_N, type(array_N[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c13e662",
   "metadata": {},
   "source": [
    "We see we have created three different types of arrays, each with a different dimensionality (`1x3`, `2x2`, `1xN`) and a different data type (`float`, `string`, `integer`, respectively). The dimensionality dictates how the matrix is indexed, an important consideration when designing your own code to analyze data. Arrays of identical dimension can perform item-by-item arithmetic operations, as well as array-wide operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5618ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array((2, 2))\n",
    "B = np.array((3, 12))\n",
    "C = A + B #Add arrays\n",
    "D = A - B #Subtract\n",
    "E = A*B #Multiply\n",
    "F = A/D #Divide\n",
    "AA = A**2 #Raise to powers\n",
    "a = np.cos(A) #Other operations \n",
    "AA = A*2 + B/4 #Mix and match\n",
    "AB = A + 2 + B*100\n",
    "CD = B/(25*A + 62) + A**2 #???\n",
    "\n",
    "print(A, B, C, D, E, F, AA, AB, CD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4448fb40",
   "metadata": {},
   "source": [
    "As long as the two arrays are **the same dimesions**, they can perform basic mathematical operatrions between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c6ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.ones(10, dtype=float)*3.2 ##Start with an array of 1's, then multiply the whole thing by 3.2\n",
    "AA = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1] ##To accomplish the same task with lists requires the for loop\n",
    "for index, ones in enumerate(AA):\n",
    "    AA[index] = AA[index]*3.2\n",
    "\n",
    "#Since arrays have a fixed size in memory, and lists do it, it is common to append iteratively through a list, then convert to an array once the loop is finished\n",
    "AA = np.array(AA)\n",
    "\n",
    "#Check to see if the two methods produce the same output\n",
    "if A.all() == AA.all():\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf82659",
   "metadata": {},
   "source": [
    "**List comprehension** is also a common way to quickly iterate over a list, and can be applied to arrays. The standard syntax for list comprehension is:\n",
    "\n",
    "newlist = [*expression* <span style=\"color:DodgerBlue\">for </span> *item* <span style=\"color:DodgerBlue\">in </span> *iterable* <span style=\"color:DodgerBlue\">if </span> *condition* == <span style=\"color:DodgerBlue\">True</span>]\n",
    "\n",
    "Note that the condition is optional if we want to apply it to all elements. We can generate the same `for` loop as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5507833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AA = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "AA = [x*3.2 for x in AA]\n",
    "AA = np.array(AA)\n",
    "if A.all() == AA.all():\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4f82f5",
   "metadata": {},
   "source": [
    "We can also **index** and **slice** arrays, just like lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25364e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 1D arrays, slicing and indexing is straightforward\n",
    "array = np.random.rand(10)\n",
    "print(array, '\\n')\n",
    "## Slicing gets you a smaller 1D array, indexing an individual element\n",
    "print(array[5:10], array[2], '\\n')\n",
    "\n",
    "#For ND arrays, you have to index N number of times to get an individual element. Indexing N - 1 times will get you a 1D array, N - 2 a 2D array, etc.\n",
    "\n",
    "array2D = np.random.rand(10,2)\n",
    "print(array2D, '\\n')\n",
    "## As before, slicing gets you a 2D array of the bottom 5 rows of the original array, indexing gets you the \n",
    "print(array2D[5:10], array2D[2],'\\n')\n",
    "\n",
    "## Slicing then indexing gets you the items in the second row\n",
    "print(array2D[5:10][1], array2D[7][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2969d9",
   "metadata": {},
   "source": [
    "### Array Creation Methods\n",
    "Often times it is difficult to know where to start when creating `Numpy` arrays. There are many methods to generate arrays of certain sizes with certain values, with some of them used above. Here are some of the basics, and [here](https://numpy.org/doc/stable/user/basics.creation.html) is more documentation on different ways to create arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff23c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a 2x2 array of 1's\n",
    "ones_array = np.ones((2, 2))\n",
    "print(ones_array)\n",
    "\n",
    "#Create a 3x2 array of 0's\n",
    "zeros_array = np.zeros((3,2))\n",
    "print(zeros_array)\n",
    "\n",
    "#Create a 1x10 array of random floats between 0 and 1\n",
    "rand_array = np.random.rand(10)\n",
    "print(rand_array)\n",
    "\n",
    "#Create an evenly spaced array between the start and stop values.\n",
    "#Default is a length of 50, can be set with 'num' argument\n",
    "even_space = np.linspace(0, 20, num=60)\n",
    "print(even_space)\n",
    "\n",
    "#Create incremented array between two values. Can set the increment by passing 'step'\n",
    "increment = np.arange(0, 20, step=0.5)\n",
    "print(increment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004bcb49",
   "metadata": {},
   "source": [
    "### Example: Analyzing a 2D Image\n",
    "Often times data will be stored in multidimensional arrays, but you'll want to isolate a specific axis. For instance, what if you had an image of an exposure from a telescope, and you wanted the median count over specific rows? Let's say we have a 64x48 grid as our image. How could we analyze this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b026c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Start with random noise on a 48 x 64 grid\n",
    "image = np.random.rand(48, 64)\n",
    "\n",
    "## Creating insert the signal into the image. Note the bounds the signal is injected into, and how rows/columns are iterated over by two for loops\n",
    "for rows, value in enumerate(image):\n",
    "    for columns, value in enumerate(value):\n",
    "        if columns > 20 and columns < 30 and rows > 20 and rows < 30:\n",
    "            image[rows][columns] += 1.25\n",
    "\n",
    "\n",
    "average_flux_columns = []\n",
    "average_flux_rows = []\n",
    "#The first for loop will have a 1D, 64 long array as the variable 'rows,' which we take the average of and append to our list above\n",
    "for rows in image:\n",
    "    average_flux_rows.append(np.average(rows))\n",
    "\n",
    "#Here's a trick: to iterate over columns instead of rows, simply use the 'array.T' method, which transposes your array. That is, rows become columns, and vice versa\n",
    "#and the dimensionality changes from 48x64 --> 64x48\n",
    "for columns in image.T:\n",
    "    average_flux_columns.append(np.average(columns))\n",
    "\n",
    "##Show our image\n",
    "plt.imshow(image)\n",
    "plt.title('A Highly Realistic Exposure from ECST (ExoCore Space Telescope)')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Rows')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "##Show the average flux of the rows as a function of columns\n",
    "plt.ylim(0.25, 1)\n",
    "plt.plot(range(0, len(average_flux_rows)), average_flux_rows)\n",
    "plt.title('Average Flux across each Row')\n",
    "plt.ylabel('Average Flux')\n",
    "plt.xlabel('Rows')\n",
    "plt.show()\n",
    "\n",
    "##Show average flux of the columns as a function of rows\n",
    "plt.ylim(0.25, 1)\n",
    "plt.title('Average Flux across each Column')\n",
    "plt.ylabel('Average Flux')\n",
    "plt.xlabel('Columns')\n",
    "plt.plot(range(0, len(average_flux_columns)), average_flux_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dabc7c3",
   "metadata": {},
   "source": [
    "The average flux as a function of both rows and columns can accurately define the location of our source! The peaks in either graph suggest that the source is centered with respect to rows, but slightly offset with respect to columns. We see this in the image!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a783b64b",
   "metadata": {},
   "source": [
    "### Handling NANS\n",
    "Another important property of arrays is the ability to **mask** values that match a certain condition. (Learn all about masking support in `Numpy` [here](https://numpy.org/devdocs/reference/routines.ma.html)). Of particular concern are masking `NANS` from datasets, which occur frequently, and will often break your analysis methods if they are left in. Let's use conditionals to mask out `NANS` in a hypothetical light curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95746b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a time array using linspace\n",
    "time = np.linspace(0, 2, num = 5000)\n",
    "\n",
    "#Generate fluxes which we start as all 1's\n",
    "flux = np.ones(5000)\n",
    "for index, data in enumerate(flux):\n",
    "    #Randomly check if we should make the current value a NAN\n",
    "    nan_check = np.random.random()\n",
    "\n",
    "    #Add some Gaussian noise\n",
    "    flux[index] = flux[index] + np.random.normal(scale=0.02)\n",
    "\n",
    "    #Add a 'transit'\n",
    "    if index > 400 and index < 1100:\n",
    "        flux[index] = flux[index] - 0.2\n",
    "    #The check if the value should be made a nan, which is a 5% chance right now\n",
    "    if nan_check < 0.05:\n",
    "        flux[index] = np.nan\n",
    "\n",
    "##Plot the result\n",
    "plt.plot(time, flux)\n",
    "plt.xlabel('Time (Days)')\n",
    "plt.ylabel('Relative Flux')\n",
    "plt.title('Plot of EC1-b')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24b1007",
   "metadata": {},
   "source": [
    "As we can see, we have simulated a transit for ExoCore1 b, but there are several spots with missing data. If we try to compute the baseline to fit our models, we run into trouble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cabe95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function checks a value to see if it's a nan or not\n",
    "def nan_checker(value):\n",
    "    if np.isnan(value) == True:\n",
    "        print('No good! NANS!')\n",
    "    elif np.isnan(value) == False:\n",
    "        print('All good! No NANS!')\n",
    "\n",
    "## Compute the baseline after the transit for modeling\n",
    "baseline = np.average(flux[100:])\n",
    "nan_checker(baseline)\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bc1810",
   "metadata": {},
   "source": [
    "As we can see, trying to find the median flux for our model returns a `NAN`. To solve this issue, we incorporate the function `np.isfinite()`. This creates a Boolean array, using `True` if it is not a `NAN`, and `False` if it is. We can then pass it through our previous array, and the resulting array will remove any present `NAN` elements. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**NOTE**: When masking **NANS**, it is important to mask any other relevant arrays associated with those data points, such as time, error, etc. Otherwise, your data will have *dimensionality mismatches*, and if not handled properly, data can be *incorrectly assigned or ignored*. This can be done by applying the same syntax **other_array[np.isfinite(flux_array_with_nanas)]** to the other arrays in your data. If the other arrays also have **NANS**, this process should be repeated for all relevant arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5050326",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Masking the data associated with NANS found in the flux array to both the NANS in the flux array, and the elements corresponding to those NANS in the time array\n",
    "new_time = time[np.isfinite(flux)]\n",
    "new_flux = flux[np.isfinite(flux)]\n",
    "\n",
    "## Check to see if we succeeded. Note how we are slicing the array after the transit!\n",
    "baseline = np.average(new_flux[100:])\n",
    "nan_checker(baseline)\n",
    "\n",
    "##Show the dimensionality differences between new and old array\n",
    "print(len(flux), len(new_flux))\n",
    "\n",
    "\n",
    "##Plot the result\n",
    "plt.plot(new_time, new_flux)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Relative Flux')\n",
    "plt.title('Plot of EC1-b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9b61ff",
   "metadata": {},
   "source": [
    "### Stacking and Exporting Arrays\n",
    "\n",
    "Often times we want to export multiple 1D arrays to a commonly readable file, such as `.csv`. Numpy has a few methods supporting this, but with some caveats:\n",
    "- Multiple arrays can stacked into columns or rows, particularly useful for 1D data\n",
    "- Stacking and exporting requires the arrays to have the **same shape** and **same data type**\n",
    "\n",
    "This is often sufficient for simple cases, but can suffer in user readability since numerical columns cannot easily have string headers. [Pandas DataFrames](https://pandas.pydata.org/docs/reference/frame.html), which has its own [lesson](Pandas.ipynb), has more robust handling for these situations; however, stacking and exporting Numpy arrays is typically more user-friendly than DataFrames, which is why we will cover both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3414caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.linspace(0, 1, num = 100)\n",
    "flux = np.random.rand(len(time))/10 + 0.95\n",
    "flux[20:30] = flux[20:30] - 0.2\n",
    "error = np.ones(len(flux))*0.05\n",
    "plt.ylim(0, 1.4)\n",
    "plt.errorbar(time, flux, yerr=error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70b074d",
   "metadata": {},
   "source": [
    "To export our data as a 3-column `.csv`, we would need to use `np.vstack` on all three of our 1D arrays, **transpose**, then pass `np.savetext` delimited by a comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "801f840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note the double parentheses! vstack takes a tuple as its argument of the arrays to be stacked. Also note the transpose! vstack as it is will save each data frame as a row,\n",
    "#so transposing makes each array a column\n",
    "X = np.vstack((time, flux, error)).T\n",
    "\n",
    "#The first argument is the directory and file name. As it is now, it will save the file in the current directory\n",
    "np.savetxt(\"Data.csv\", X, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf4074e",
   "metadata": {},
   "source": [
    "What if we wanted to export the [image](#example-analyzing-a-2d-image) from before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f58cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple! Just save it as is\n",
    "np.savetxt(\"Image.csv\", image, delimiter=',')\n",
    "\n",
    "#To convince yourself this worked, we can read it back in using np.genfromtxt\n",
    "import_image = np.genfromtxt(\"Image.csv\", delimiter=',')\n",
    "plt.imshow(import_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52262872",
   "metadata": {},
   "source": [
    "### Sorting & Searching\n",
    "Often times when working with data it is useful to be able to sort and search in particular ways. This brief section will go over some available functions relevant to these in `Numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c46da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Sorting methods\n",
    "data = np.random.normal(10, 1, 10)\n",
    "print(data)\n",
    "#In ascending order\n",
    "data = np.sort(data)\n",
    "print(data)\n",
    "#Descending order. Negatives will sort it in ascending order, then applying another negative gives the original array back in descending order\n",
    "data = -np.sort(-data)\n",
    "print(data)\n",
    "#In-place sorting\n",
    "data.sort()\n",
    "print(data)\n",
    "\n",
    "##Searching methods\n",
    "data = np.random.normal(10, 1, 10)\n",
    "print(data)\n",
    "#Gives index of largest argument\n",
    "x= data.argmax()\n",
    "print(x, data[x])\n",
    "#Ibid for minimum\n",
    "a= data.argmin()\n",
    "print(a, data[a])\n",
    "#Return elements if they satisfy certain condition(s)\n",
    "print(np.where(data < 10), data[np.where(data < 10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb2b851",
   "metadata": {},
   "source": [
    "## Mathematical Routines\n",
    "[Here](https://numpy.org/devdocs/reference/routines.html) is the official documentation on `Numpy` routines!\n",
    "\n",
    "This section will cover the important mathematical routines present in `Numpy`. This is not exhaustive, but will cover some of the most useful functions and classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63f7a94",
   "metadata": {},
   "source": [
    "### Basic Mathematical Functions\n",
    "These are your typical functions, like: $$\\sin(x), \\exp(x), \\cosh(x), \\ln(x) \\cdots$$ If it exists, there is a good chance `Numpy` supports it! Since there is a long list, we will not enumerate these functions here. The [documentation](https://numpy.org/devdocs/reference/routines.math.html) for all supported functions described them in depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353ebed5",
   "metadata": {},
   "source": [
    "### Statistics\n",
    "`Numpy` provides highly efficient and convenient functions to find basic statistics of e.g. arrays. Here are some examples and a demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867624f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw random Gaussian points with mean 50, standard deviation of 1 \n",
    "mu, sigma = 50, 1\n",
    "data = np.random.normal(mu, sigma, 10000)\n",
    "#Verify mean\n",
    "mu = np.mean(data)\n",
    "#Standard Deviation + Variance\n",
    "sigma = np.std(data)\n",
    "sigma2 = np.var(data)\n",
    "#Percentiles, 95th in this example\n",
    "p = np.percentile(data, 0.95)\n",
    "#Quantiles, 95th in this example\n",
    "q = np.quantile(data, 0.95)\n",
    "print(mu)\n",
    "print(sigma, sigma2)\n",
    "print(p, q)\n",
    "\n",
    "##Create histogram of data, using probability density as opposed to counts\n",
    "count, bins, ignored = plt.hist(data, bins=50, density = True)\n",
    "\n",
    "##Plot the model to compare to\n",
    "plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n",
    "               np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
    "         linewidth=2, color='black', linestyle=':', label = 'Model')\n",
    "\n",
    "##Show lines marking off different stanard deviations of the distribution\n",
    "plt.axvline(mu + sigma, color = 'red', linestyle = '--', label = '1$\\sigma$')\n",
    "plt.axvline(mu - sigma, color = 'red', linestyle = '--')\n",
    "plt.axvline(mu + 2*sigma, color = 'green', linestyle = '--', label = '2$\\sigma$')\n",
    "plt.axvline(mu - 2*sigma, color = 'green', linestyle = '--')\n",
    "plt.axvline(mu + 3*sigma, color = 'orange', linestyle = '--', label = '3$\\sigma$')\n",
    "plt.axvline(mu - 3*sigma, color = 'orange', linestyle = '--')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Probability density')\n",
    "plt.title('Gaussian Data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f86cdd0",
   "metadata": {},
   "source": [
    "`numpy.random` is one of the best sources for random number generation (RNG). If you need to implement e.g. Monte Carlo methods from scratch, it's an excellent choice. `Numpy`'s statistic support is largely confined to the normal distribution. The [lesson (TBD)](../Data_Structures/Scipy.ipynb) on [Scipy](https://docs.scipy.org/doc/scipy/index.html) discusses other distributions, like Poisson and log-normal, that are highly relevant to astronomy and astrophysics research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b55c35",
   "metadata": {},
   "source": [
    "### Linear Algebra\n",
    "The last class of methods in this lesson is for linear algebra methods. As mentioned in the prelude, arrays are based on matrices, and consequently many methods performed on matrices (e.g. finding eigenvalues, eigenvectors, determinants, etc.) are supported by `Numpy`. If some of these topics do not sound familiar, here is an excellent [reference](https://tutorial.math.lamar.edu/classes/de/la_eigen.aspx), and here is the [documentation](https://numpy.org/devdocs/reference/routines.linalg.html) for the functions not covered here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b1bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array(([1, 3, 4], [5, 6, 7], [8, 9, 4]))\n",
    "B = np.array(([6, 5, 7], [4, 0, 2], [4, 11, 12]))\n",
    "#Compute the determinant, only on square arrays\n",
    "print(np.linalg.det(A))\n",
    "#Compute the trace\n",
    "print(np.trace(A))\n",
    "#Compute the inverse matrix\n",
    "print(np.linalg.inv(A))\n",
    "#Matrix Multiplication\n",
    "print(np.matmul(A, B))\n",
    "\n",
    "#Eigenvalues and eigenvectors, only on square arrays\n",
    "values, vectors = np.linalg.eig(A)\n",
    "print(values, vectors)\n",
    "\n",
    "C = np.array([1, 5, 12])\n",
    "D = np.array([5, 10, 22])\n",
    "#Compute the norm of a vector\n",
    "print(np.linalg.norm(C))\n",
    "#Compute the inner (dot) product of two vectors\n",
    "print(np.dot(C, D), np.inner(C,D))\n",
    "#Outer product\n",
    "print(np.outer(C,D))\n",
    "#Cross product of 1D vectors\n",
    "print(np.cross(C,D))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a1ac08",
   "metadata": {},
   "source": [
    "Additionally, `Numpy` can solve **systems of equations**. For instance, to solve the system \n",
    "\n",
    "- $x_{0} + 5 x_{1} = 12$\n",
    "- $14 x_{0} + 2 x_{1} = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ea1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coefficients\n",
    "a = np.array([[1, 5],[14, 2]])\n",
    "#Equal to\n",
    "b = np.array([12, 2])\n",
    "x = np.linalg.solve(a, b)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d37f9e",
   "metadata": {},
   "source": [
    "### Simple Polynomial Regression Methods\n",
    "\n",
    "Another useful feature of `NumPy` is linear/polynomial regressions. This is done using the `polynomial` module. To perform a linear fit, we can use the function `np.polynomial.polynomial.fit`. An example is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf602336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression slope: 1.0456045436099974 \n",
      "Regression y-intercept: 1.8667707600545325\n"
     ]
    }
   ],
   "source": [
    "def noisy_linear(x,m,b):\n",
    "    return m*x + b + np.ones(len(x))*np.random.normal(0, 1, len(x))\n",
    "x = np.linspace(0,5, num=100)\n",
    "## Pass noisy linear data with slope 1, y-intercept 2\n",
    "y = noisy_linear(x, 1, 2)\n",
    "\n",
    "## The arguments are x-data, y-data, and polynomial order. For linear, order = 1, quadratic order = 2, etc.\n",
    "b, m = np.polynomial.polynomial.polyfit(x,y,1)\n",
    "print('Regression slope: ' + str(m), '\\nRegression y-intercept: ' + str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67d2d4a",
   "metadata": {},
   "source": [
    "More advanced curve fitting routines are available in the `scipy` module. The lesson will be avaiable [here](../Data_Structures/Scipy.ipynb) once written."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1f704e",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "To help solidify your understanding of `Numpy`, here are some exercises.\n",
    "\n",
    "### Problem 1: Creating an Array in Four Different Ways\n",
    "Generate a 1D array with length 100, starting from 0 in increments of 2, up to 200, in the following ways:\n",
    "- Using a `for` loop, lists, and the `range()` function\n",
    "- Using `np.ones()`\n",
    "- Using `np.linspace`\n",
    "- Using `np.arange`\n",
    "Make sure each dtype is float! Compare the contents of each one using `np.array.all()`, and return `True` if all four are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c450f3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Codespace for Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a45ab3",
   "metadata": {},
   "source": [
    "### Problem 2: Handling NANs\n",
    "Write a function that takes in any number of `Numpy` arrays of the same length, and returns the same 1D arrays with `NANs` removed **across identical indices**. That is, if a `NAN` occurs at index 5 for list1, remove index 5 across all lists, such that all returned lists are the same length. Check your results by using the `nan_checker()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a11e7080",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Codespace for Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49a54cd",
   "metadata": {},
   "source": [
    "### Problem 3: Modeling Ingress and Egress\n",
    "When generating data for the example lightcurve of EC-1 b, we assumed a very simplistic model of an exoplanet transit that ignores the 'ingress' and 'egress,' the time when the planet enters/exits the cross-section of its host with respect to our line-of-sight. Our model is very 'boxy', with no smooth transition from non-transiting to transiting. We can try to improve on this through linear interpolation. \n",
    "\n",
    "**By modifying the `time` and `flux` arrays from the EC-1 b example, model a one hour ingress/egress by linearly interpolating from the baseline flux to the transit-depth flux. HINT: Look at the code to figure out the transit depth!**\n",
    "\n",
    "**NOTE: The `time` array is in days, so be sure to convert!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d681f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Codespace for Problem 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exocore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
